{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKKJG1ZIry5apNNU0IDXe1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almonfrey/MAI-Course/blob/main/class_8_log_reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "89zEnv4jVZje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "from sklearn.metrics import f1_score, accuracy_score, log_loss\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "wBVEu2YPccWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "xRdevPjyVWBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX608LM-ZJAX"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "url = \"https://raw.githubusercontent.com/Almonfrey/MAI-Course/main/data/winequality-white.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Downloaded Data\")\n",
        "df[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Transformation"
      ],
      "metadata": {
        "id": "cQlM3XJ7oHP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target transformation\n",
        "df['quality'] = df['quality'].apply(lambda x: 0 if x < 6 else 1)"
      ],
      "metadata": {
        "id": "1WgI5_UwoCWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset"
      ],
      "metadata": {
        "id": "vv0a4kLjVTTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "train_set, temp_set = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(train_set)}\")\n",
        "print(f\"Validation set size: {len(val_set)}\")\n",
        "print(f\"Test set size: {len(test_set)}\")"
      ],
      "metadata": {
        "id": "9GIT9LYN0eAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Preprocess Pipeline"
      ],
      "metadata": {
        "id": "Uv4-m_aJbNs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline\n",
        "preprocess = Pipeline([\n",
        "    (\"standardize\", StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "5wTx2X2ObM1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include Predictor and Train Model"
      ],
      "metadata": {
        "id": "8GGB3DsNXceD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include predictor in the pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])\n",
        "# Fit log_reg\n",
        "y_train = train_set['quality']\n",
        "X_train = train_set.drop('quality', axis=1)\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9qAggGyaXeka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics"
      ],
      "metadata": {
        "id": "Jl9bKMUtkCtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train set Evaluation"
      ],
      "metadata": {
        "id": "xNeNpUzkhOdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on training data\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_train_proba = pipeline.predict_proba(X_train)[:, 1]  # Probability for AUC\n",
        "\n",
        "# Evaluation metrics (use y_train, not y_val!)\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "loss_train = log_loss(y_train, y_train_proba)\n",
        "precision_train = precision_score(y_train, y_train_pred)\n",
        "recall_train = recall_score(y_train, y_train_pred)\n",
        "auc_train = roc_auc_score(y_train, y_train_proba)\n",
        "f1_train = f1_score(y_train, y_train_pred)\n",
        "\n",
        "print(f\"Accuracy Train: {accuracy_train:.3f}\")\n",
        "print(f\"Log loss Train: {loss_train:.3f}\")\n",
        "print(f\"Precision Train: {precision_train:.3f}\")\n",
        "print(f\"Recall Train: {recall_train:.3f}\")\n",
        "print(f\"AUC Train: {auc_train:.3f}\")\n",
        "print(f\"F1 Score Train: {f1_train:.3f}\")"
      ],
      "metadata": {
        "id": "1zEicwNni_VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Set Evaluation"
      ],
      "metadata": {
        "id": "hTMhGI9OiIvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation data\n",
        "y_val = val_set['quality']\n",
        "X_val = val_set.drop('quality', axis=1)\n",
        "y_val_pred = pipeline.predict(X_val)\n",
        "y_val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
        "loss_val = log_loss(y_val, y_val_proba)\n",
        "precision_val = precision_score(y_val, y_val_pred)\n",
        "recall_val = recall_score(y_val, y_val_pred)\n",
        "auc_val = roc_auc_score(y_val, y_val_proba)\n",
        "f1_val = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"\\nAccuracy Val: {accuracy_val:.3f}\")\n",
        "print(f\"Log loss Val: {loss_val:.3f}\")\n",
        "print(f\"Precision Val: {precision_val:.3f}\")\n",
        "print(f\"Recall Val: {recall_val:.3f}\")\n",
        "print(f\"AUC Val: {auc_val:.3f}\")\n",
        "print(f\"F1 Score Val: {f1_val:.3f}\")"
      ],
      "metadata": {
        "id": "uob3WaN3iICN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Set Evaluation"
      ],
      "metadata": {
        "id": "kB2zaDW3iY0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on testing data\n",
        "y_test = test_set['quality']\n",
        "X_test = test_set.drop('quality', axis=1)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "loss_test = log_loss(y_test, y_test_proba)\n",
        "precision_test = precision_score(y_test, y_test_pred)\n",
        "recall_test = recall_score(y_test, y_test_pred)\n",
        "auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nAccuracy Test: {accuracy_test:.3f}\")\n",
        "print(f\"Log loss Test: {loss_test:.3f}\")\n",
        "print(f\"Precision Test: {precision_test:.3f}\")\n",
        "print(f\"Recall Test: {recall_test:.3f}\")\n",
        "print(f\"AUC Test: {auc_test:.3f}\")\n",
        "print(f\"F1 Score Test: {f1_test:.3f}\")"
      ],
      "metadata": {
        "id": "DU78EkMghYhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}