{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4oBL4SNohNQ8lDOEEteTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almonfrey/MAI-Course/blob/main/class6_practical_activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "L3G3R6DkWRtC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKaYuBBOU3sZ"
      },
      "outputs": [],
      "source": [
        "# Standard imports for data analysis\n",
        "import pandas as pd  # Data processing\n",
        "import numpy as np  # Numerical computing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visualization imports\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Matplotlib configuration for inline display (Jupyter only)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "4edvBHJsWyYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the housing dataset and display the first 5 rows\n",
        "df = pd.read_csv(\"data/us_house_sales.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "QkcwCG_ZWuis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data formatting"
      ],
      "metadata": {
        "id": "wqoKwytM1LZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display current data types before formatting\n",
        "print('Data types BEFORE formatting:')\n",
        "print(df.dtypes)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# 1. Price - remove $ and commas, convert to float\n",
        "df['Price'] = pd.to_numeric(\n",
        "    df['Price'].astype(str).str.replace(r'[\\$,]', '', regex=True),\n",
        "    errors='coerce'\n",
        ").astype(float)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# 2. Bedrooms - extract number, allow NaN, use nullable Int type\n",
        "df['Bedrooms'] = pd.to_numeric(\n",
        "    df['Bedrooms'].str.extract(r'(\\d+)')[0],\n",
        "    errors='coerce'\n",
        ").astype(int)\n",
        "\n",
        "# 3. Bathrooms - same as bedrooms\n",
        "df['Bathrooms'] = pd.to_numeric(\n",
        "    df['Bathrooms'].str.extract(r'(\\d+)')[0],\n",
        "    errors='coerce'\n",
        ").astype(int)\n",
        "\n",
        "# 4. Area (Sqft) - remove text and commas, convert to float\n",
        "df['Area (Sqft)'] = pd.to_numeric(\n",
        "    df['Area (Sqft)'].str.replace(r'[^\\d.]', '', regex=True),\n",
        "    errors='coerce'\n",
        ").astype(float)\n",
        "\n",
        "# 5. Lot Size - same as area\n",
        "df['Lot Size'] = pd.to_numeric(\n",
        "    df['Lot Size'].str.replace(r'[^\\d.]', '', regex=True),\n",
        "    errors='coerce'\n",
        ").astype(float)\n",
        "\n",
        "# Verify formatting results\n",
        "print('\\nData types AFTER formatting:')\n",
        "print(df[['Price', 'Bedrooms', 'Bathrooms', 'Area (Sqft)', 'Lot Size']].dtypes)"
      ],
      "metadata": {
        "id": "BVdl_YhH4C05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning"
      ],
      "metadata": {
        "id": "FOd1tjYLl-hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for duplicate records"
      ],
      "metadata": {
        "id": "QEwryNNuzd65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate records\n",
        "\n",
        "# Number of duplicate records BEFORE removal\n",
        "num_duplicates_before = df.duplicated().sum()\n",
        "print(f'\\nNumber of duplicate records BEFORE removal: {num_duplicates_before}')\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Number of duplicate records AFTER removal (should be 0)\n",
        "num_duplicates_after = df.duplicated().sum()\n",
        "print(f'Number of duplicate records AFTER removal: {num_duplicates_after}')"
      ],
      "metadata": {
        "id": "hil6mHy2zaVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset"
      ],
      "metadata": {
        "id": "0ggrV1ADRDOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "train_set, temp_set = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(train_set)}\")\n",
        "print(f\"Validation set size: {len(val_set)}\")\n",
        "print(f\"Test set size: {len(test_set)}\")"
      ],
      "metadata": {
        "id": "uCIi73KERCyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing value treatment"
      ],
      "metadata": {
        "id": "QzXylQfDl_zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Value Treatment\n",
        "print('Missing values BEFORE cleaning:')\n",
        "print(train_set.isnull().sum())\n",
        "\n",
        "# Strategy for each column:\n",
        "median_year = train_set['Year Built'].median()\n",
        "train_set.fillna({'Lot Size': train_set['Area (Sqft)'], 'Year Built': median_year}, inplace=True)\n",
        "train_set.dropna(subset=['Price', 'Area (Sqft)', 'Property Type'], inplace=True)\n",
        "\n",
        "print('Missing values AFTER cleaning:')\n",
        "print(train_set.isnull().sum())"
      ],
      "metadata": {
        "id": "3hje8yMVmMRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing outliers"
      ],
      "metadata": {
        "id": "T9Di0TIb0HQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier Detection using the IQR method\n",
        "\n",
        "# Calculate the first (Q1) and third quartiles (Q3) of the 'Price' column\n",
        "Q1 = train_set['Price'].quantile(0.25)\n",
        "Q3 = train_set['Price'].quantile(0.75)\n",
        "\n",
        "# Compute the Interquartile Range (IQR)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define lower and upper bounds for detecting outliers\n",
        "price_lower_bound = Q1 - 1.5 * IQR\n",
        "price_upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Print the calculated bounds for reference\n",
        "print(f'\\nPrice bounds for outlier detection: Lower: {price_lower_bound:,.2f}, Upper: {price_upper_bound:,.2f}')\n",
        "\n",
        "# Count outliers BEFORE filtering\n",
        "outliers_before = train_set[(train_set['Price'] < price_lower_bound) | (train_set['Price'] > price_upper_bound)]\n",
        "num_outliers_before = len(outliers_before)\n",
        "print(f'Number of outliers detected before filtering: {num_outliers_before}')\n",
        "\n",
        "# Filter out the outliers\n",
        "train_set = train_set[(train_set['Price'] >= price_lower_bound) & (train_set['Price'] <= price_upper_bound)]\n",
        "\n",
        "# Count outliers AFTER filtering (should be zero)\n",
        "outliers_after = train_set[(train_set['Price'] < price_lower_bound) | (train_set['Price'] > price_upper_bound)]\n",
        "num_outliers_after = len(outliers_after)\n",
        "print(f'Number of outliers detected after filtering: {num_outliers_after}')"
      ],
      "metadata": {
        "id": "8HxJsLp80JiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data validity check"
      ],
      "metadata": {
        "id": "hwbumZKntVZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Validity Checks per category\n",
        "\n",
        "# Number of invalid entries BEFORE filtering\n",
        "print(\"Invalid entries BEFORE filtering:\")\n",
        "print(f\"Price: {(train_set['Price'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Area (Sqft): {(train_set['Area (Sqft)'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Bedrooms: {(train_set['Bedrooms'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Year Built: {(train_set['Year Built'] <= 1800).sum()} invalid entries\")\n",
        "\n",
        "# Apply all validity conditions to filter the dataframe\n",
        "train_set = train_set[(train_set['Price'] > 0) &\n",
        "        (train_set['Area (Sqft)'] > 0) &\n",
        "        (train_set['Bedrooms'] > 0) &\n",
        "        (train_set['Year Built'] > 1800)]\n",
        "\n",
        "# Number of invalid entries AFTER filtering (should be zero)\n",
        "print(\"\\nInvalid entries AFTER filtering:\")\n",
        "print(f\"Price: {(train_set['Price'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Area (Sqft): {(train_set['Area (Sqft)'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Bedrooms: {(train_set['Bedrooms'] <= 0).sum()} invalid entries\")\n",
        "print(f\"Year Built: {(train_set['Year Built'] <= 1800).sum()} invalid entries\")"
      ],
      "metadata": {
        "id": "cNTVyOkU00XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final check"
      ],
      "metadata": {
        "id": "C72oX8wA1dYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final missing value check\n",
        "print('\\nMissing values AFTER cleaning:')\n",
        "print(train_set.isnull().sum())"
      ],
      "metadata": {
        "id": "3g_isvdL1e8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}